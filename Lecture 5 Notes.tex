\documentclass[14pt]{extarticle}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{scribe}
\usepackage{listings}
\usepackage{relsize}
\usepackage{xlop}
\usepackage{multirow,bigdelim,dcolumn,booktabs}
\usepackage[linesnumbered,vlined]{algorithm2e}
\usepackage{tikz}
\usepackage{float}
\usetikzlibrary{trees}
\usetikzlibrary{positioning}

\Scribe{Aditya Diwakar}
\Lecturer{Frederic Faulkner}
\LectureNumber{5}
\LectureDate{January 25, 2022}
\LectureTitle{Modular Arithmetic}

\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}

\lstset{style=mystyle}
\setlength{\parindent}{0pt}

\begin{document}
	\MakeScribeTop

    Homework 2 (1B) is out and due on Saturday. Further, I also posted an
    announcement on how to properly format an algorithm for homeworks.

    \section*{Modular Arithmetic}
    What is $2 + 2$? Pretty easy, it's obviously $1 \Mod{3}$. Modulo
    simply means the remainder after dividing two numbers. 
    \begin{align*}
        a\Mod{b}
    \end{align*}
    is \texitt{equal} to the remainder of $a$ after dividing it by $b$. For
    example, $37\Mod{5} = 2$ since $37 = (7\cdot 5) + 2$. A popular
    example of modulo arithmetic is clocks where the 24-hour time format
    is $\Mod{24}$.\\

    A more formal definition for this class is talking about $a$ and $b$
    in the modulo classes. In notation, we write
    \begin{align*}
        a\equiv b\Mod{n}\quad\text{or}\quad a\equiv_N b
    \end{align*}
    if $a$ and $b$ are part of the same modulo class. For example:
    \begin{align*}
        -2\equiv_3 1\equiv_3 4\equiv_3 7\equiv_3 10
        \quad
        \text{or}
        \quad
        -1\equiv_3 2\equiv_3 5\equiv_3 8
    \end{align*}
    In the left, all numbers are $1\Mod{3}$ and in the second, they are
    $2\Mod{3}$\\

    If $x\equiv_N x^\prime$ and $y\equiv_N y^\prime$, then the following
    are true:
    \begin{enumerate}
        \item $x + y\equiv_N x^\prime + y^\prime$
        \item $xy \equiv_N x^\prime y^\prime$
        \item $x^c \equiv_N (x^\prime)^c$
    \end{enumerate}

    \pagebreak 

    These operations are useful, as you can compute calculations such as
    $321\cdot 165 \Mod{160}$ where you could naively multiply $321$ and $165$
    first and then apply the modulo \textit{or} you could take the modulo
    first and only need to multiply $321\Mod{160} \cdot 165\Mod{160} \equiv
    1\cdot 5 \Mod{160} \equiv 5$\\

    Similarly, you could compute $2^{210} \Mod{31}$ by doing:
    \begin{align*}
        2^{210} \equiv_{31} \left(2^5\right)^{42} \equiv_{31} (32)^{42} 
        \equiv_{31} 1^{42} \equiv_{31} 1
    \end{align*}

    \section{Modular Arithmetic Algorithms}
    What is the time complexity for the \texttt{mod} operation? We can write
    a division algorithm that returns the quotient and remainder written as:

    \begin{algorithm}[H]
        \SetKwFunction{FMain}{Div}
        \SetKwProg{Fn}{Function}{:}{}
        \Fn{\FMain{$x, y$}}{
            \If{$x = 0$}{
                \Return $0,0$
            }
            $q, r \gets \Call{\FMain{$\lfloor \frac{x}{2} \rfloor, y$}}$    \\
            $q, r \gets 2q, 2r$                                             \\
            \If{$x$ is odd}{
                $r = r + 1$
                \tcp{error when flooring $x / 2$}
            }   
            \tcc{$r > y$ means remainder overflowed divisor}
            \If{$r > y$}{
                $q = q + 1$
                \tcp{an additional copy of $y$ fits in $x$}
                $r = r - y$
                \tcp{reduce remainder by overflow amount}
            }
            \Return $q, r$
        }
    \end{algorithm}

    For this algorithm, the doubling of $q, r$ are $O(1)$ and all other
    operations are $O(n)$ as we could have an $n$ long carry when adding
    numbers together ($q = q + 1, r = r - y$, etc). Hence, the non-recursive
    work is $O(n)$\\

    The recursive call has a size of $n - 1$ since we divide $x$ by 2
    which removes a bit meaning the recurrence relation is:
    \begin{align*}
        T(n) = T(n - 1) + O(n) = O(n^2)
    \end{align*}
    This is $O(n^2)$ because there are roughly $n$ calls with roughly $O(n)$.

    \subsection{Addition under Modulo}
    What is the time complexity for \texttt{addmod} (addition under a modulo)?
    If we assume that we are given inputs $x, y$ that are both already under
    $\Mod{n}$, then we don't need to worry about modding them again.\\

    Hence, we can simply perform $(x + y)mod N$ which takes $O(n)$ time
    and since $x < N, y < N$, then $x + y < 2N$ so if $x + y \geq N$, we
    can subtract $N$.\\

    In total, $O(n)$ for addition, $O(n)$ for comparision (subtraction and
    determining sign), gives a total of $O(n)$ runtime for addition with
    mod.

    \subsection{Multiplication under Modulo}
    What is the time complexity for \texttt{multmod} (multiplication under
    a modulo)? Under the same assumptions as above: $xy \Mod{n}$ requires
    $xy$ multiplication which can take $O(n^{\log_2 3})$ and then computing
    the modulo takes $O(n^2)$ making multiplication under modulo an $O(n^2)$
    operation.

    \subsection{Exponentiation under Modulo}
    What is the time complexity for \texttt{modexp} (exponentiation under
    modulo)? A bad implementation for this could be to multiply:
    \begin{align*}
        &x\Mod{N}       \\
        &x^2\Mod{N}     \\
        &x^3\Mod{N}     \\
        &\vdots         \\
        &x^y\Mod{N} 
    \end{align*}
    and multiply them together which is a total of $y$ multiplications, giving
    you $O(2^n)$ multiplications (which is very bad). Rather, we need
    to compute $x$ taken to a power $2^i$ for multiple values $i$.\\

    An alternative method can be constructed after realizing that any number
    $x^y$ can be written as $x^{2^ny_n + \cdots + 2^1y_1 + 2^0y_0}$ where
    $y_i$ are the bits of $y$. Due to exponentiation rules, this is equivelant
    to:
    \begin{align*}
        x^{2^ny_n + \cdots + 2^1y_1 + 2^0y_0}
        =
        x^{2^ny_n}\cdots x^{2^1y_1} \cdot x^{2^0y_0}
    \end{align*}
    Since these constructions are equivelant, we only need to compute
    $x^{2^i}$ for $i\in [0, n-1]$ as any exponentiated number can be 
    reconstructed with these $n$ numbers. 

    How long does this method take? Since we need to multiply $x^{2^i}$ for
    $i\in [0, n-1]$, we are doing $n$ multiplications which each take $O(n^2)$
    giving a runtime of $O(n^3)$ to compute our table of exponentiated $x$.\\

    The $O(n^2)$ multiplication comes from the fact that when squaring the
    number, there is a possibility of overflowing under modulo requiring us
    to call the \texttt{mod} algorithm again (with runtime $O(n^2)$).\\

    Then, to reconstruct $x^y$, $y$ can have as many $n$ bits potentially
    requiring $n$ total multiplications which also has a runtime of $O(n^3)$.
    Hence, the \texttt{modexp} algorithm is $O(n^3) + O(n^3) = O(n^3)$.\\

    As an example, let's compute $7^{25} \Mod{23}$ and since $25 = (11001)_2$
    then, we need to compute $2^{2^0}, 2^{2^1}, 2^{2^2}, 2^{2^3}, 2^{2^4}$ 
    all under $\Mod{23}$:
    \begin{align*}
        7^{2^0} &= 7^1 = 7                                              \\
        7^{2^1} &= 7^2 = 49 \equiv_{23} 3                               \\
        7^{2^2} &= 7^2 \cdot 7^2 \equiv_{23} 3\cdot 3\equiv_{23} 9      \\
        7^{2^3} &= (7^{2^2})^2 \equiv_{23} 9^2 \equiv_{23} 12           \\
        7^{2^4} &= (7^{2^3})^2 \equiv_{23} 12^2 \equiv_{23} 6
    \end{align*}

    Hence, we can combine these together to compute $7^{25}$ as:
    \begin{align*}
        7^{25} = 7^{2^4 + 2^3 = 2^0} = 7^{2^4} 7^{2^3} 7^{2^0} \equiv_{23}
        6\cdot 12\cdot 7\equiv_{23} 504 \equiv_{23} 21
    \end{align*}
    meaning we can reach our final conclusion of $7^{25} \equiv 21 \Mod{23}$.\\

    \subsection{Division under Modulo}
    What is the time complexity of \texttt{divmod} (division under modulo)?
    Since fractions don't exist within modular arithmetic, this becomes
    slightly complicated. For example, how can we solve $5x \equiv_7 3$? By
    inspection, we can find $x = 2$ would give $10 \equiv_7 3$ which is true.\\

    More precisely, if we can find some number $a\cdot 5 = 1$, then
    we say $a$ is the multiplicative inverse of $5\Mod{7}$. In this case,
    $a = 3$ as $3\cdot 5 = 15 \equiv_7 1$.\\

    The multiplicative inverse is powerful because:
    \begin{align*}
        5x &\equiv_7 3              \\
        3(5x)   &\equiv_7 3\cdot 3    \\
        15x     &\equiv_7 9           \\
        x       &\equiv_7 2     
    \end{align*}
    which is a more robust way of finding that $x = 2$. But, how did we 
    find the multiplicative inverse (the value $a$ from above)? It doesn't
    always exist!

    \begin{theorem*}
        $x$ only has a multiplicative inverse modulo $N$ if $gcd(x, N) = 1$
    \end{theorem*}
    In other words, the inverse only exists if $x$ and $N$ are relatively
    prime.

    \section{Greatest Common Denominator}
    $\gcd(a, b)$ is the largest integer that divides both $a$ and $b$. How do
    we find it?\\

    One way is to factor both numbers and pick the largest factors:
    \begin{align*}
        gcd(24, 54) = gcd(3\cdot 2\cdot 2\cdot 2, 3\cdot 3\cdot 3\cdot 2)
        = 3 \cdot 2 = 6
    \end{align*}
    We picked out $3\cdot 2$ because both numbers had $3\cdot 2$ as multiplied
    factors. However, this method relies on factoring which is an extremely
    slow operation, so rather: we use the Euclidean Algorithm!

    \subsection{Euclidean Algorithm}
    % gcd(x, y):
    %   if y == 0: return x
    %   return gcd(x, x mod y)
    \begin{algorithm}[H]
        \SetKwFunction{FMain}{gcd}
        \SetKwProg{Fn}{Function}{:}{}
        \Fn{\FMain{$x, y$}}{
            \If{$y = 0$}{
                \Return $x$
            }
            \Return \Call{\FMain{$x, x\Mod{y}$}}
        }
    \end{algorithm}

    Performing $x\Mod{y}$ takes $O(n^2)$ time so the non-recursive work is
    $O(n^2)$ and we make a single recursive call with size $n - 1$ because
    after two calls of this function, the input goes from $(x, y)
    \to (x, x \Mod{y}) \to (x\Mod{y}, \cdots)$ and $x\Mod{y}$ is bounded by
    $x / 2$ meaning we have reduced the number of bits by $1$ giving a final
    running time recurrence relation of
    \begin{align*}
        T(n) = T(n - 1) + O(n^2) = O(n^3)
    \end{align*}
    This is $O(n^3)$ as we are making roughly $n$ total calls with $O(n^2)$
    work per call giving a total of $nO(n^2) = O(n^3)$.\\

    % fact without proof: we can write gcd(x, y) as a sum...
    % gcd(x, y) = ax + by (for some a, b)
    % there exists an algorithm to find a, b

    An interesting fact regarding GCDs is that we can always write
    $gcd(x, y)$ as a linear combination of $x$ and $y$:
    \begin{align*}
        gcd(x, y) = ax + by
    \end{align*}
    But, what is the important of this form? From an above theorem, a 
    multiplicative inverse only exists for $x\Mod{N}$ if $gcd(x, N) = 1$.\\

    This form allows us to say:$gcd(x, N) = 1$ then $1 = ax + bN$.
    \begin{align*}
        gcd(x, N) = 1\implies 1 = ax + bN &\implies 1\Mod{n} = (ax + bN)\Mod{N}
                                            \\
                                          &\implies ax\equiv 1\Mod{n}
    \end{align*}
    Hence, if there exists an algorithm to find values $a, b$ such that
    $gcd(x, y) = ax + by$ then we can find the multiplicative inverse if $x$
    and $N$ are relatively prime.\\

    \pagebreak 

    The algorithm to find these values is known as the Extended Euclidean
    algorithm:

    \begin{algorithm}[H]
        \SetKwFunction{FMain}{extgcd}
        \SetKwProg{Fn}{Function}{:}{}
        \Fn{\FMain{$x, y$}}{
            \If{$y = 0$}{
                \Return $x, 1, 0$
            }
            $d, a^\prime, b^\prime \gets \Call{\FMain{$y, x\Mod{y}$}}$  \\
            $a^{\prime\prime}, b^{\prime\prime} \gets 
                b^\prime, a^\prime - \left\lfloor \dfrac{x}{y} \right\rfloor
                \cdot b^\prime$                                         \\
            \Return $d, a^{\prime\prime}, b^{\prime\prime}$
        }
    \end{algorithm}

    The runtime of the non-recursive work is $O(n^2)$ as we are computing
    $x\Mod{y}$ and are performing a recursion with size $n - 1$ giving a
    recurrence relation that is the same as the Euclidean algorithm:
    \begin{align*}
        T(n) = T(n - 1) + O(n^2) = O(n^3)
    \end{align*}
\end{document}
