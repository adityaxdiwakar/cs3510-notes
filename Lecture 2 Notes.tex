\documentclass[14pt]{extarticle}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{scribe}
\usepackage{listings}
\usepackage{relsize}
\usepackage{xlop}
\usepackage{multirow,bigdelim,dcolumn,booktabs}
\usepackage[linesnumbered,vlined]{algorithm2e}
\usepackage{tikz}
\usetikzlibrary{trees}
\usetikzlibrary{positioning}

\Scribe{Aditya Diwakar}
\Lecturer{Frederic Faulkner}
\LectureNumber{2}
\LectureDate{January 13, 2022}
\LectureTitle{Multiplication \& D\&C}

\lstset{style=mystyle}
\setlength{\parindent}{0pt}

\begin{document}
	\MakeScribeTop

    Homework 1 will be released either today (Thursday) or tomorrow (Friday)
    and due a week afterwards (either Friday or Saturday of next week).

    \section{Addition and Multiplication}
    This class will generally focus on these concepts from an algorithmic 
    perspective. In particular, we generally analyze these topics using
    binary. We now wonder what the runtime (big-O) is for addition.\\
    \begin{center}
        \begin{tabular}{ccccccc}
          && 1 & 1 & 1 & 0 & 0 \\
         +&& 1 & 0 & 1 & 1 & 0\\
        \hline
          & 1 & 1 & 0 & 0 & 1 & 0
        \end{tabular}
    \end{center}
    The algorithm for addition is as follows:
    \begin{enumerate}
        \item For each column, we either add 2 or 3 (including carry bit)
            digits which is $O(1)$ (a small lookup table)
    \end{enumerate}
    Hence, the runtime for this algorithm is $O(n)$ where $n$ is the number
    of bits that are being added. We can't do better as this is a linear 
    algorithm and at the very least, we have to traverse each bit regardless.\\

    \pagebreak
    For multiplication of two binary numbers $a$ and $b$, we perform an
    algorithm in two phases (note: $n$ is the length of $a$ or $b$)
    % add example for 1010 x 1101 = 10000010
    \begin{center}
        \begin{tabular}{ccccccccc}
            & & & & 1 & 0 & 1 & 0           \\
            & & & x & 1 & 1 & 0 & 1         \\
            \hline
            & & & & 1 & 0 & 1 & 0 & 
             \rdelim\}{4}{10mm}[\parbox{3cm}{$n$ numbers}]   \\
            + & & & 0 & 0 & 0 & 0 &         \\
           + & & 1 & 0 & 1 & 0 & &          \\
           + & 1 & 0 & 1 & 0 & & &          \\
           \hline
           1 & 0 & 0 & 0 & 0 & 0 & 1 & 0
        \end{tabular}
    \end{center}
    \begin{enumerate}
        \item Multiply digit by digit which will create $n$ numbers
            with total length $\leq 2n$ and $n \cdot 2n = O(n^2)$
        \item Add these numbers together such that we get $n - 1$
            additions of numbers of length $\leq 2n$ creating a total
            runtime of $2n \cdot (n - 1) = O(n^2)$
    \end{enumerate}

    \subsection{Challenge Question / Discussion} 
    What is the time complexity of multiplying $m$ bit by $n$ bit number?\\

    We still have two phases in this multiplication:
    \begin{enumerate}
        \item Multiply digit by digit which will create $n$ numbers that
            are of a different size! Now, each number has a maximum size
            of $m$ meaning this step takes a total time of $O(nm)$
        \item In a similar fashion, we now have to add together $\approx n-1$
            numbers of numbers that have length $m$ with a runtime of
            $O(nm)$
    \end{enumerate}
    Hence, the runtime for multiplying two numbers with length $n$ and $m$ bits
    gives a runtime of $O(nm)$.
    \hfill
    $\square$

    \pagebreak
    \subsection{Divide and Conquer}
    Can we make a faster algorithm to multiply numbers? We want to find an
    algorithm faster than $O(n^2)$ for two $n$-bit numbers.\\

    \textbf{Idea:} Split the multiplication into smaller subproblems
    and recursively solve. Finally, aggregate all the subsolutions to get
    a final solution.
    \begin{center}
        \begin{tabular}{ccccccccc}
            & & & & 1 & 0 & 1 & 1           \\
            & & & x & 1 & 0 & 1 & 1         \\
            \hline
        \end{tabular}
    \end{center}
    % insert example 1011 x 1011 = 1010 x (100 * 10 + 11)
    \begin{enumerate}
        \item In the above example, split the top $(1011)_2$ into $(10)_2$
            shifted by 2 and $(11)_2$ to create two seperate multiplication
            subproblems where a 4 bit number is multiplied by a 2 bit number.
        \item In the 2 subproblems, split the bottom $(1011)_2$ into $(10)_2$
            shifted by 2 and $(11)_2$ to create a total of four seperate
            multiplication subproblems.
        \item Continue this splitting until we only have to multiply 1 bit
            numbers together (base case, $1\times 0 = 0\times 1 = 0\times 0
            = 0$ and $1\times 1 = 1$).
    \end{enumerate}
    \begin{center}
        \begin{tikzpicture}[level distance=2cm,
          level 1/.style={sibling distance=8cm},
          level 2/.style={sibling distance=4cm}]
          \node {$(1011)_2 \times (1011)_2$}
            child {node {$(1011)_2 \times (10)_2$}
              child {node {$(10)_2 \times (10)_2$}}
              child {node {$(11)_2 \times (10)_2$}}
            }
            child {node {$(1011)_2 \times (11)_2$}
              child {node {$(10)_2 \times (11)_2$}}
              child {node {$(11)_2 \times (11)_2$}}
            };
        \end{tikzpicture}
    \end{center}
    For brevity, the rest of the tree is not drawn. Further, the above tree
    is more verbose than reality. Splitting from $1 \to 4$ multiplications
    happens in one step by splitting both $a$ and $b$ into halves on each
    step. The next two steps in the tree would split into a total of $16$ 
    multiplications each of which contain $1$ bit to multiply.\\

    In order to reconstruct the final solution, we add together children on
    the same level and shift the left sibling (as the left sibling
    solves for the left half of the final output). This algorithm is formalized
    below.

    \subsection{Formalized D\&C Multiplication}
    \textbf{Problem:} Multiply two numbers $x$ and $y$ together\\[2mm]
    \textbf{Algorithm:} 
    \begin{enumerate}
        \item Split $x$ into $x_L$ and $x_R$ and $y$ into $y_L$ and $y_R$ 
            being the left and right halves
            \begin{center}
                \begin{tikzpicture}
                    \node[draw,
                        rect,
                        minimum width=4cm,
                        minimum height=1.2cm,
                    ] (xrect) at (0,0){$x$};

                    \node[draw,
                        rect,
                        minimum width=4cm,
                        minimum height=1.2cm,
                        below=0.4cm of xrect
                    ] (yrect){$y$};

                    \node [draw,
                        minimum width=2cm,
                        minimum height=1.2cm,
                        right=2cm of xrect
                    ]  (xl) {$x_L$};
                    \node [draw,
                        minimum width=2cm,
                        minimum height=1.2cm,
                        right=0cm of xl
                    ]  (xr) {$x_R$};

                    \node [draw,
                        minimum width=2cm,
                        minimum height=1.2cm,
                        right=2cm of yrect
                    ]  (yl) {$y_L$};
                    \node [draw,
                        minimum width=2cm,
                        minimum height=1.2cm,
                        right=0cm of yl
                    ]  (yr) {$y_R$};

                    \draw[-stealth] (yrect.east) -- (yl.west) 
                        node[midway,above]{};
                    \draw[-stealth] (xrect.east) -- (xl.west) 
                        node[midway,above]{$split$};

                    \end{tikzpicture}
            \end{center}

        \item With these splits, we can still represent $x$ and $y$ 
            using $x = 2^{n/2} x_L + x_R$ (same applies for $y$)

        \item This form gives us $xy = 2^n(x_L y_L) + 2^{n/2} (x_R y_L + x_L
            y_R) + x_R y_R$
    \end{enumerate}
    In a sense, we can compute $x \times y$ by using the halves of the numbers.
    In the above equation, how do we compute $x_L y_L$? This is where recursion
    and divide and conquer comes in! $x_L y_L$ is computed with the same
    equation as above with \textit{its own halves}. Here is pseudocode that
    makes the recursion more obvious.
    \newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
    \SetCommentSty{mycommfont}
    \begin{algorithm}
        \SetKwFunction{FMain}{Mult}
        \SetKwProg{Fn}{Function}{:}{}
        \Fn{\FMain{$x, y$}}{
            \tcc{split x, y into left and right halves (bitwise)}
            $x_L \gets x[0 : n/2]$      \\
            $x_R \gets x[n/2 : n]$      \\
            $y_L \gets y[0 : n/2]$      \\
            $y_R \gets y[n/2 : n]$      \\
            \tcc{recursion to multiply smaller numbers, all of size n / 2}
            $A \gets$ \Call{\FMain{$x_L, y_L$}} \\
            $B \gets$ \Call{\FMain{$x_L, y_R$}} \\
            $C \gets$ \Call{\FMain{$x_R, y_L$}} \\
            $D \gets$ \Call{\FMain{$x_R, y_R$}} \\
            \tcc{put everything together, see equation from above}
            \Return $2^n A + 2^{n/2} (B + C) + D$
            \tcp*{combining takes $O(n)$ time}
        }
    \end{algorithm}

    \begin{definition}
        $T(n)$ is \textit{number} of steps an algorithm takes for input size $n$
    \end{definition}

    In the above algorithm, it takes $O(n)$ time to get halves and combine
    the answer for the final return. On top of that, we make $4$ total
    calls to multiply numbers of size $n/2$, hence $T(n)$ is:
    \begin{align*}
        T(n) = O(n) + 4T\left(\frac{n}{2}\right)
    \end{align*}

    As of now, we can't solve this for a runtime -- but it is $O(n^2)$. You
    will be able to solve this later in the course. This runtime is the same
    as the naive grade school multiplication, \textit{but...}
    Notice the following:
    \begin{align*}
        (x_L + x_R)(y_L + y_R) &= x_Ly_L + x_Ry_R + x_Ly_R + x_Ry_L\\
        (x_L + x_R)(y_L + y_R) - x_Ly_L - x_Ry_R &= x_Ly_R + x_Ry_L
    \end{align*}
  
    From above, recall $A = x_Ly_L$, $D = x_Ry_R$ so the above is equivelant
    to
    \begin{align*}
        \underbrace{(x_L + x_R)(y_L + y_R)}_{\text{single multiplication}} 
        - A - B &= \underbrace{B + C}_{\text{two multiplications}}
    \end{align*}
    Hence, define a new value $Q = (x_L + x_R)(y_L + y_R)$ which is still
    a multiplication of smaller numbers as $x_L + x_R \neq 2^{n/2} x_L + x_R$.
    This gives a new algorithm:
    \begin{algorithm}
        \SetKwFunction{FMain}{Mult}
        \SetKwProg{Fn}{Function}{:}{}
        \Fn{\FMain{$x, y$}}{
            $x_L \gets x[0 : n/2]$      \\
            $x_R \gets x[n/2 : n]$      \\
            $y_L \gets y[0 : n/2]$      \\
            $y_R \gets y[n/2 : n]$      \\
            $A \gets$ \Call{\FMain{$x_L, y_L$}} \\
            $B \gets$ \Call{\FMain{$x_L, y_R$}} \\
            \tcp{new multiplication, but no more $B$ and $C$}\\
            $Q \gets$ \Call{\FMain{$x_L + x_R, y_L + y_R$}} \\
            \Return $2^n A + 2^{n/2} (Q - A - D) + D$
            \tcp*{combining still $O(n)$}
        }
    \end{algorithm}

    In this algorithm, we still take $O(n)$ time to perform additions and
    subtractions but only make $3$ recursive calls, giving a recurrence of:
    \begin{align*}
        T(n) = O(n) + 3T\left(\frac{n}{2}\right)
    \end{align*}
    This is $O\left(n^{\log_2 3}\right) \approx O\left(n^{1.59}\right)$ as you
    will be able to solve next week.
\end{document}
