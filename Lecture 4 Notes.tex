\documentclass[14pt]{extarticle}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{scribe}
\usepackage{listings}
\usepackage{relsize}
\usepackage{xlop}
\usepackage{multirow,bigdelim,dcolumn,booktabs}
\usepackage[linesnumbered,vlined]{algorithm2e}
\usepackage{tikz}
\usepackage{float}
\usetikzlibrary{trees}
\usetikzlibrary{positioning}

\Scribe{Aditya Diwakar}
\Lecturer{Frederic Faulkner}
\LectureNumber{4}
\LectureDate{January 20, 2022}
\LectureTitle{Master Theorem}

\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{blue}{#1}}
\SetCommentSty{mycommfont}

\lstset{style=mystyle}
\setlength{\parindent}{0pt}

\begin{document}
	\MakeScribeTop

    Same announcement as previous lecture regarding homework. Homework 1 
    due Saturday. Homework 2 released Saturday. Also, join Piazza.\\

    \section{Master Theorem}
    Most of us can agree that expanding a recurrence relationship is painful,
    and very easy to make a mistake while simplifying. The Master Theorem is
    a powerful theorem that lets us find the running time of any recurrence
    relation of the form:
    \begin{align*}
        T(n) = aT\left(\frac{n}{b}\right) + O\left(n^d\right)
    \end{align*}
    In fact, based on $a, b, d$, we can find $T(n)$ as:
    \begin{align*}
        T(n) = \begin{cases}
            O\left(n^d\right)           & a < b^d      \\
            O\left(n^d\log n)           & a = b^d      \\
            O\left(n^{\log_b a}\right)  & a > b^d
        \end{cases}
    \end{align*}
    The proof of this theorem is not reproduced here, but can be easily
    found online. Essentially, the proof follows by manually expanding the
    generic recurrence from above. The geometric sum rules from the previous
    lecture helps here.

    \subsection{Example}
    Our naive slow multiplication method can be solved using this theorem:
    \begin{align*}
        T(n) = 4T\left(\frac{n}{2}\right) + O(n) \implies a = 4, b = 2, d = 1
    \end{align*}
    and hence (by the Master Theorem), $4 > 2^1$ so $T(n) = O(n^{\log_2 4})
    = O(n^2)$.\\

    Hypothetically, let's say instead the recurrence was:
    \begin{align*}
        T(n) = 4T\left(\frac{n}{2}\right) + O(n^2) \implies a = 4, b = 2, d = 2
    \end{align*}
    and hence (by the Master Theorem), $4 = 2^2$ so $T(n) = O(n^d\log n)
    = O(n^2\log n)$

    \section{Divide and Conquer}
    We've briefly mentioned on what divide and conquer is, but let's talk about
    it some more. Divide and Conquer is a general algorithm strategy where if
    we can break a question into smaller pieces, and combine the solutions
    to those smaller problems.

    \subsection{MergeSort}
    An alteration of this sort of this problem is something where we are 
    performing some action on a list, such as what is done by MergeSort.
    \begin{enumerate}
        \item Split list recursively
        \item When list contains $\leq 2$ elements, a base case is reached
                and sort this
        \item Reconstruct by performing a \texttt{merge} operation on the
            sub-solutions
    \end{enumerate}

    How does the \texttt{merge} operation work? 
    \begin{enumerate}
        \item Create a pointer on the first element of each list
        \item Pick the smaller of the two pointed elements, move the relevant
            pointer
        \item Continue this process until no more elements in one list
        \item Add the rest of the elements from the other list
    \end{enumerate}

    The recurrence relation is $T(n) = 2T\left(\frac{n}{2}\right) + O(n)$
    where $a = 2, b = 2, d = 1$ implying that $T(n) = O(n\log n)$.\\

    \begin{algorithm}[H]
        \SetKwFunction{FMain}{MergeSort}
        \SetKwFunction{FMerge}{Merge}
        \SetKwProg{Fn}{Function}{:}{}
        \Fn{\FMain{$L$}}{
            \tcc{split L into two halves}
            $RetL \gets []$
            $L_a \gets L[: \frac{|L|}{2}]$      \\
            $L_b \gets L[\frac{|L|}{2} : ]$     \\
            \tcc{MergeSort two halves}
            $ML_a \gets \Call{\FMain{$L_a$}}$   \\  
            $ML_b \gets \Call{\FMain{$L_b$}}$   \\
            \tcc{Merge sorted halves}
            $\Call{\FMerge{$L_a, L_a, RetL$}}$ \\
            \Return $RetL$
        }

        \Fn{\FMerge{$L_1, L_2, L$}}{
            \tcc{append the rest of \textit{other} list if one is empty}
            \If{$|L_1| = 0 \lor |L_2| = 0$}{
                \Return $L + L_1 + L_2$ 
            }
            \tcc{pick smaller element; recursively move pointer}
            \If{$L_1[1] \leq L_2[1]$}{
                $L.append(L_1[1])$      \\
                \Call{\FMerge{$L_1[1:], L_2, L$}}   
            }
            \Else{
                $L.append(L_2[1])$      \\
                \Call{\FMerge{$L_1, L_2[1:], L$}}   
            }
        }
    \end{algorithm}

    \subsection{Median}
    Another form of this question is \texttt{Median}. This type of algorithm
    attempts to find the median (middle) element of an $n$ list. A naive
    way is to sort the list and return the $n / 2$ element. Since sorting
    has a runtime of $O(n\log n)$, then this method also has that same runtime.
    \\

    However, instead, we choose to generalize. Instead of solving for only the
    median, we can make a new algorithm: \texttt{QuickSelect} which gives the
    $k^{th}$ smallest element from a list $L$. This will work for the median
    as we can set $k = |L| / 2$.\\

    \subsection{Quick Select}
    The objective of \texttt{QuickSelect} is to pick the $kth$ smallest element
    from a list $L$. Hence, it is parameterized as: \texttt{QuickSelect(L, k)}.\\

    The first step of QuickSelect is to pick a random pivot $p$ from the 
    elements of $L$. This takes $O(1)$. Then, we perform a linear search
    through $L$ partitioning $L$ into:

    \begin{center}
        \begin{tikzpicture}
            \node[draw,
                rect,
                minimum width=4cm,
                minimum height=1.2cm,
            ] (Llist) at (0,0){$L$};

            \node [draw,
                minimum width=2cm,
                minimum height=1.2cm,
                right=2cm of Llist
            ]  (ll) {$L_l$};
            \node [draw,
                minimum width=2cm,
                minimum height=1.2cm,
                right=0cm of ll
            ]  (lm) {$L_m$};
            \node [draw,
                minimum width=2cm,
                minimum height=1.2cm,
                right=0cm of lm
            ]  (lr) {$L_r$};

            \draw[-stealth] (Llist.east) -- (ll.west) 
                node[midway,above]{split};
            \end{tikzpicture}
    \end{center}
    
    where $L_l$ are all elements in $L$ less than $p$, $L_r$ are all elements
    in $L$ greater than $P$, and $L_m$ are all the elements equal to $p$.
    For example, $L = [1, 4, 7, 10, 3, 2, 6, 8]$ and $k = 5$ and randomly
    let $p = 4$, then we split as so:
 
    \begin{center}
        \begin{tikzpicture}
            \node[draw,
                rect,
                minimum width=4cm,
                minimum height=1.2cm,
            ] (Llist) at (0,0){$[1, 4, 7, 10, 3, 2, 6, 8]$};

            \node [draw,
                minimum width=2cm,
                minimum height=1.2cm,
                right=2cm of Llist
            ]  (ll) {$[1, 3, 2]$};
            \node [draw,
                minimum width=2cm,
                minimum height=1.2cm,
                right=0cm of ll
            ]  (lm) {$[4]$};
            \node [draw,
                minimum width=2cm,
                minimum height=1.2cm,
                right=0cm of lm
            ]  (lr) {$[7, 10, 6, 8]$};

            \draw[-stealth] (Llist.east) -- (ll.west) 
                node[midway,above]{split};
            \end{tikzpicture}
    \end{center}
    Since $k = 5$, then we know that it can't be in $L_l$ or $L_m$ because
    $|L_l| + |L_m| = 4$. Also, because of our pivot, we know that both $L_l$
    and $L_m$ are $\leq 4$. Hence, we know our answer lives in $L_r$. When
    recursing into $L_r$, we can't use $k = 5$ (obviously: $|L_r| < 5$), but
    instead we choose $k - |L_l| - |L_m|$. In this example, that yields $1$
    meaning we look for the smallest element in $L_r$.\\

    Another rule: if the smallest element lies in $L_m$, then we don't need
    to recurse as $L_m = \{x\mid x \in L \land x = p\}$ so all elements 
    in $L_m$ are equal to the same element and we can simply return the pivot.

    \begin{algorithm}[H]
        \SetKwFunction{FMain}{QuickSelect}
        \SetKwProg{Fn}{Function}{:}{}
        \Fn{\FMain{$L, k$}}{
            \tcc{get random pivot}
            $p\gets \text{random pivot $\in L$}$            \\
            $L_l \gets L[0 : \frac{|L|}{3}]$                  \\
            $L_m \gets L[\frac{|L|}{3}: \frac{2|L|}{3}]$    \\
            $L_r \gets L[\frac{2|L|}{3}: |L|]$    \\
            \tcc{three cases of where $kth$ smallest lives}
            \If{$k\leq |L_1|$} {
                \Return \Call{\FMain{$L_l, k$}}
            }
            \ElseIf{$|L_l| < k \leq |L_l| + |L_m|$}{
                \tcc{simply return pivot as $L_m$ only contains $p$}
                \Return $p$
            }
            \ElseIf{$|L_l| + |L_m| < k$}{
                \Return \Call{\FMain{$L_r, k - |L_l| - |L_m|$}}
            }
        }
    \end{algorithm}

    Clearly, each \textit{level} of this function call takes $O(n)$ time
    as the partitioning requires a linear scan to compare based on the pivot
    (a total of $n - 1$ comparisions). However, what isn't clear is the number
    of recursions and the size of that recursion.\\

    Since the pivot is picked randomly, it complicates the runtime calculation.
    However, we know if our pivot is between the $25^{th}$ and $75^{th}$ 
    percentile, then we can reduce the size of the list to $3/4 n$.\\

    Further, $P\left(\text{picking good pivot}\right) = P\left(
    \text{picking pivot in middle $50\%$}\right) = \frac{1}{2}$ meaning we
    expect to take $2$ iterations before getting a good pivot.\\

    Hence, the runtime can be computed as:
    \begin{align*}
        T(n) = T\left(\frac{3n}{4}\right) 
            + \underbrace{O(n) + O(n)}_{\text{expected 2 tries to get good pivot}}
    \end{align*}
    However, $2O(n) = O(n)$ giving us a final runtime of:
    \begin{align*}
        T(n) = T\left(\frac{3n}{4}\right) + O(n)
    \end{align*}
    which is equal to $O(n)$ (by Master Theorem: $a = 1, b = 4/3, d = 1$).
\end{document}
